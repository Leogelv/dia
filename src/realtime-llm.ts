import OpenAI from 'openai';
import { OpenAIAssistant } from './openai-assistant';

export class RealtimeLLM {
  private openai: OpenAI;
  private assistant: OpenAIAssistant;

  constructor(apiKey: string, assistantId: string) {
    this.openai = new OpenAI({
      apiKey: apiKey,
      dangerouslyAllowBrowser: true
    });
    this.assistant = new OpenAIAssistant(apiKey, assistantId);
  }

  async initialize() {
    await this.assistant.initialize();
  }

  async *streamResponse(userMessage: string) {
    console.log('üöÄ Starting realtime stream for:', userMessage);

    // –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    const assistantResponse = await this.assistant.getResponse(userMessage);
    console.log('üìù Got assistant response:', assistantResponse);

    // –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∏–º —Å –æ—Ç–≤–µ—Ç–æ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    const stream = await this.openai.chat.completions.create({
      model: "gpt-4-1106-preview",
      messages: [
        {
          role: "system",
          content: "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ä—É—Å—Å–∫–æ–≥–æ–≤–æ—Ä—è—â–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∫—Ä–∞—Å–∏–≤–æ –∏ –≥—Ä–∞–º–æ—Ç–Ω–æ –æ–∑–≤—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –¥—Ä—É–≥–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, —Ä–∞–∑–±–∏–≤–∞—è –µ–≥–æ –Ω–∞ —É–¥–æ–±–Ω—ã–µ –¥–ª—è –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è —á–∞—Å—Ç–∏."
        },
        { 
          role: "user", 
          content: `–û–∑–≤—É—á—å —ç—Ç–æ—Ç –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: ${assistantResponse}` 
        }
      ],
      stream: true,
      temperature: 0.7,
      max_tokens: 150
    });

    // –°—Ç—Ä–∏–º–∏–º –æ—Ç–≤–µ—Ç –ø–æ —á–∞—Å—Ç—è–º
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content;
      if (content) {
        console.log('üìù Streaming chunk:', content);
        yield content;
      }
    }
  }

  async cleanup() {
    await this.assistant.cleanup();
  }
} 