import OpenAI from 'openai';
import { OpenAIAssistant } from './openai-assistant';

export class RealtimeLLM {
  private openai: OpenAI;
  private assistant: OpenAIAssistant;

  constructor(apiKey: string, assistantId: string) {
    this.openai = new OpenAI({
      apiKey: apiKey,
      dangerouslyAllowBrowser: true
    });
    this.assistant = new OpenAIAssistant(apiKey, assistantId);
  }

  async initialize() {
    await this.assistant.initialize();
  }

  async *streamResponse(userMessage: string) {
    console.log('üöÄ Starting realtime stream for:', userMessage);

    const tools = [
      {
        type: "function" as const,
        function: {
          name: "getAssistantResponse",
          description: "–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ HeyGen",
          parameters: {
            type: "object",
            properties: {
              message: {
                type: "string",
                description: "–°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É"
              }
            },
            required: ["message"]
          }
        }
      }
    ];

    const stream = await this.openai.chat.completions.create({
      model: "gpt-4-1106-preview",
      messages: [
        {
          role: "system",
          content: `–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ä—É—Å—Å–∫–æ–≥–æ–≤–æ—Ä—è—â–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. 
          –í–ê–ñ–ù–û: –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∏–ª–∏ –ø—Ä–æ—Å–∏—Ç –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –Ω–µ–º—É - 
          –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–π —Ñ—É–Ω–∫—Ü–∏—é getAssistantResponse –∏ –ø–µ—Ä–µ–¥–∞–π —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
          –í –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö –æ—Ç–≤–µ—á–∞–π —Å–∞–º –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.`
        },
        { role: "user", content: userMessage }
      ],
      stream: true,
      temperature: 0.7,
      max_tokens: 150,
      tools: tools,
      tool_choice: {
        type: "function",
        function: { name: "getAssistantResponse" }
      }
    });

    let currentMessage = '';
    let isToolCallStarted = false;

    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content;
      if (content) {
        console.log('üìù Streaming chunk:', content);
        yield content;
      }

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏
      const toolCall = chunk.choices[0]?.delta?.tool_calls?.[0];
      if (toolCall?.type === 'function' && 
          toolCall.function?.name === 'getAssistantResponse' && 
          toolCall.function?.arguments && 
          !isToolCallStarted) {
        try {
          isToolCallStarted = true;
          const args = JSON.parse(toolCall.function.arguments);
          console.log('üîÑ Calling assistant with message:', args.message);
          const response = await this.assistant.streamResponse(args.message);
          for await (const assistantChunk of response) {
            console.log('ü§ñ Assistant chunk:', assistantChunk);
            yield assistantChunk;
          }
        } catch (error) {
          console.error('Error calling assistant:', error);
          throw new Error('–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞');
        }
      }
    }
  }

  async cleanup() {
    await this.assistant.cleanup();
  }
} 