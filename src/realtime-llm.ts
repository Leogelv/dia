import OpenAI from 'openai';
import { OpenAIAssistant } from './openai-assistant';

export class RealtimeLLM {
  private openai: OpenAI;
  private assistant: OpenAIAssistant;

  constructor(apiKey: string, assistantId: string) {
    this.openai = new OpenAI({
      apiKey: apiKey,
      dangerouslyAllowBrowser: true
    });
    this.assistant = new OpenAIAssistant(apiKey, assistantId);
  }

  async initialize() {
    await this.assistant.initialize();
  }

  async *streamResponse(userMessage: string) {
    console.log('üöÄ Starting realtime stream for:', userMessage);

    const tools = [
      {
        type: "function" as const,
        function: {
          name: "getAssistantResponse",
          description: "–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ HeyGen",
          parameters: {
            type: "object",
            properties: {
              message: {
                type: "string",
                description: "–°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É"
              }
            },
            required: ["message"]
          }
        }
      }
    ];

    const stream = await this.openai.chat.completions.create({
      model: "gpt-4-1106-preview",
      messages: [
        {
          role: "system",
          content: "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ä—É—Å—Å–∫–æ–≥–æ–≤–æ—Ä—è—â–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π —Ñ—É–Ω–∫—Ü–∏—é getAssistantResponse –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."
        },
        { role: "user", content: userMessage }
      ],
      stream: true,
      temperature: 0.7,
      max_tokens: 150,
      tools: tools,
      tool_choice: "auto"
    });

    let currentMessage = '';

    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content;
      if (content) {
        console.log('üìù Streaming chunk:', content);
        yield content;
      }

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏
      const toolCall = chunk.choices[0]?.delta?.tool_calls?.[0];
      if (toolCall?.type === 'function' && toolCall.function?.name === 'getAssistantResponse' && toolCall.function?.arguments) {
        try {
          const args = JSON.parse(toolCall.function.arguments);
          const response = await this.assistant.streamResponse(args.message);
          for await (const assistantChunk of response) {
            console.log('ü§ñ Assistant chunk:', assistantChunk);
            yield assistantChunk;
          }
        } catch (error) {
          console.error('Error calling assistant:', error);
        }
      }
    }
  }

  async cleanup() {
    await this.assistant.cleanup();
  }
} 